# 质量属性



## Specifying Qulity Attributes

准确的定义质量属性对在架构层面上进行评估是十分有必要的。

质量属性场景是用来定义目标质量属性的重要方法。

场景是有着确定结构的简单句子，两类主要的场景是：

1.  通用场景是系统独立的场景，目的是去引导整个质量属性需求
2. 具体场景是系统相关的场景，目的是去构建在质量属性在具体应用上的定义。 这是通用场景的一种扩展。



#### General Scenarios

* 通用场景提供了一个去产生大量的通用，系统独立的质量属性场景的框架。
* 每个质量属性都潜在的但不是必然和我们处理的系统相关。
* 为了让通用场景对与具体的系统产生作用，我们必须把针对系统进行定制。

##### 组成元素

* Stimulus:  当到达系统时一个需要被考虑到的条件。
* Source of Stimulus:  一个产生刺激的实体。
* Response:  当刺激到达后产生的行动
* Response Meassure:   对刺激的回应必须在某种程度上可以进行测量，这样对应的需求才可以被检验。
* 环境， 当刺激发生时系统处于的条件。 
* Artifat: 整个系统或者需求对应的系统的一部分。

#### Tactics

TODO: 



#### 质量设计决策

一共有7种类型的决策：

1. 职责的分配
2. coordination model
3. Data model
4. management of resources
5. Mapping among architecture elements
6. Binding time decisions
7. Choice of technology





#### 可用性

##### Source 

###### general 

Internal/external: people, hardware, software, physical infrastructure, physical environment 

###### concrete

Heartbeat/Monitor



##### Stimulus 

###### general 

Fault: omission, crash, incorrect timing, incorrect response 

###### concrete

Server unresponsive



##### Artifact 

###### general

Processors, communication channels, persistent storage, processes 

###### concrete

Process



##### Environment 

###### general 

Normal operation,startup,shutdown,repair mode,degraded operation, overloaded operation 

###### concrete

Normal operation



##### Response 

###### general

Prevent the fault from becoming a failure 

Detect the fault: 

- Log the fault 
- Notify appropriate entities (people or systems) 

Recover from the fault: 

- Disable source of events causing the fault 
- Be temporarily unavailable while repair is being effected 
- Fix or mask the fault/failure or contain the damage it causes 
- Operate in a degraded mode while repair is being effected 



###### concrete

Inform operator continue to operate



#####Response Measure 

###### general

Time or time interval when the system must be available Availability percentage (e.g., 99.999%)
 Time to detect the fault
 Time to repair the fault 

Time or time interval in which system can be in degraded mode Proportion (e.g., 99%) or rate (e.g., up to 100 per second) of a certain class of faults that the system prevents, or handles without failing 

###### concrete

No downtime





#### 性能

##### Source 

###### general 

Internal or external to the system

###### concrete

Users



##### Stimulus 

###### general 

Arrival of a periodic, sporadic, or stochastic event

###### concrete

Initiate Transactions



##### Artifact 

###### general

System or one or more components in the system

###### concrete

System



##### Environment 

###### general 

Operational mode: normal, emergency, peak load, overload

###### concrete

Normal operation



##### Response 

###### general

Process events, change level of service

###### concrete

Transactions Are Processed



##### Response Measure 

###### general

Latency, deadline, throughput, jitter, miss rate

###### concrete

Average Latency  of Two  Seconds



#### 互操作性

##### Source 

###### general 

A system initiates a request to interoperate with another system

###### concrete

Our Vehicle Information System



##### Stimulus 

###### general 

A request to exchange information among system(s).

###### concrete

Current Location Sent



##### Artifact 

###### general

The systems that wish to interoperate.

###### concrete

Traffic Monitoring System



##### Environment 

###### general 

System(s) wishing to interoperate are discovered at runtime or known prior to runtime.

###### concrete

Systems known prior to run-time



##### Response 

###### general

One or more of the following: 

- The request is (appropriately) rejected and appropriate 

  entities (people or systems) are notified. 

- The request is (appropriately) accepted and information is 

  exchanged successfully. 

- The request is logged by one or more of the involved 

  systems.

###### concrete

Traffic Monitor Combines Current Location with Other
Information, Overlays on Google Maps, and Broadcasts



##### Response Measure 

###### general

​	One or more of the following: 

1. * Percentage of information exchanges correctly processed 

2. * Percentage of information exchanges correctly rejected 

###### concrete

​       Our Information Included Correctly 99.9% of the Time



#### 安全性

##### Source 

###### general 

Human or another system which may have been previously identified (either correctly or incorrectly) or may be currently unknown. A human attacker may be from outside the organization or from inside the organization.

###### concrete

Disgruntled Employee from Remote Location 



##### Stimulus 

###### general 

Unauthorized attempt is made to display data, change or delete data, access system services, change the system’s behavior, or reduce availability.

###### concrete

Attempts to Modify Pay Rate



##### Artifact 

###### general

System services, data within the system, a component or resources of the system, data produced or consumed by the system

###### concrete

Data within the System



##### Environment 

###### general 

The system is either online or offline; either connected to or disconnected from a network; either behind a firewall or open to a network; fully operational, partially operational, or not operational.

###### concrete

Normal Operations



##### Response 

###### general

- Transactions are carried out in a fashion such that 

  - Data or services are protected from unauthorized access. 

  - Data or services are not being manipulated without authorization. 

  - Parties to a transaction are identified with assurance. 

  - The parties to the transaction cannot repudiate their 

    involvements. 

  - The data, resources, and system services will be available for 

    legitimate use.
     The system tracks activities within it by 

  - Recording access or modification 

  - Recording attempts to access data, resources, or services 

  - Notifying appropriate entities (people or systems) when an 

    apparent attack is occurring 

###### concrete

System Maintains Audit Trail



##### Response Measure 

###### general

One or more of the following: 

1. - How much of a system is compromised when a particular 

     component or data value is compromised 

   - How much time passed before an attack was detected 

   - How many attacks were resisted 

   - How long does it take to recover from a successful attack 

   - How much data is vulnerable to a particular attack  

###### concrete

Correct Data Is Restored within a Day and Source of Tampering Identified





#### 可修改性

##### Source 

###### general 

End user, developer, system administrator

###### concrete

Developer



##### Stimulus 

###### general 

A directive to add/delete/modify functionality, or change a quality attribute, capacity, or technology

###### concrete

Wishes  to Change  UI



##### Artifact 

###### general

Code, data, interfaces, components, resources, configurations,

###### concrete

Code



##### Environment 

###### general 

Runtime, compile time, build time, initiation time, design time

###### concrete

Design Time



##### Response 

###### general

One or more of the following: 

- Make modification 
- Test modification 
- Deploy modification 

###### concrete

Change made and unit tested



##### Response Measure 

###### general

1. Cost in terms of the following: 

2. 1. - Number, size, complexity of affected artifacts 

      - Effort 

      - Calendar time 

      - Money (direct outlay or opportunity cost) 

      - Extent to which this modification affects other functions or 

        quality attributes 

      - New defects introduced 

###### concrete

In Three Hours





#### 可测试性

##### Source 

###### general 

Unit testers, integration testers, system testers, acceptance testers, end users, either running tests manually or using automated testing tools

###### concrete

Unit Tester



##### Stimulus 

###### general 

A set of tests is executed due to the completion of a coding increment such as a class layer or service, the completed integration of a subsystem, the complete implementation of the whole system, or the delivery of the system to the customer.

###### concrete

Code Unit Completed



##### Artifact 

###### general

The portion of the system being tested

###### concrete

Code Unit



##### Environment 

###### general 

Design time, development time, compile time, integration time, deployment time, run time

###### concrete

Development



##### Response 

###### general

One or more of the following: execute test suite and capture results, capture activity that resulted in the fault, control and monitor the state of the system

###### concrete

Results Captured



##### Response Measure 

###### general

1. 1. One or more of the following: effort to find a fault or class of
      faults, effort to achieve a given percentage of state space
      coverage, probability of fault being revealed by the next
      test, time to perform tests, effort to detect faults, length of
      longest dependency chain in test, length of time to prepare
      test environment, reduction in risk exposure (size(loss) ×
      prob(loss))

###### concrete

85% Path Coverage in Three Hours









## ASR 



**16.1 Gathering aSrs from requirements documents** 

An obvious location to look for candidate ASRs is in the requirements documents or in user stories. After all, we are looking for requirements, and requirements should be in requirements documents. Unfortunately, this is not usually the case, although as we will see, there is information in the requirements documents that can be of use. 

**don’t Get your Hopes up** 

Many projects don’t create or maintain the kind of requirements document that professors in software engineering classes or authors of traditional software en- gineering books love to prescribe. Whether requirements are specified using the “MoSCoW” style (must, should, could, won’t), or as a collection of “user sto- ries,” neither of these is much help in nailing down quality attributes. 

Furthermore, no architect just sits and waits until the requirements are “fin- ished” before starting work. The architect *must* begin while the requirements are still in flux. Consequently, the QA requirements are quite likely to be up in the air when the architect starts work. Even where they exist and are stable, require- ments documents often fail an architect in two ways. 

First, most of what is in a requirements specification does not affect the architecture. As we’ve seen over and over, architectures are mostly driven or “shaped” by quality attribute requirements. These determine and constrain the most important architectural decisions. And yet the vast bulk of most require- ments specifications is focused on the required features and functionality of a system, which shape the architecture the least. The best software engineering practices do prescribe capturing quality attribute requirements. For example, the Software Engineering Body of Knowledge (SWEBOK) says that quality attribute requirements are like any other requirements. They must be captured if they are important, and they should be specified unambiguously and be testable. 

In practice, though, we rarely see adequate capture of quality attribute re- quirements. How many times have you seen a requirement of the form “The system shall be modular” or “The system shall exhibit high usability” or “The system shall meet users’ performance expectations”? These are not requirements, but in the best case they are invitations for the architect to begin a conversation about what the requirements in these areas really are. 

Second, much of what is useful to an architect is not in even the best re- quirements document. Many concerns that drive an architecture do not manifest themselves at all as observables in the system being specified, and so are not the subject of requirements specifications. ASRs often derive from business goals in the development organization itself; we’ll explore this in Section 16.3. De- velopmental qualities are also out of scope; you will rarely see a requirements document that describes teaming assumptions, for example. In an acquisition context, the requirements document represents the interests of the acquirer, not that of the developer. But as we saw in Chapter 3, stakeholders, the technical environment, and the organization itself all play a role in influencing architectures.

**Sniffing Out aSrs from a requirements document** 

Although requirements documents won’t tell an architect the whole story, they are an important source of ASRs. Of course, ASRs aren’t going to be conve- niently labeled as such; the architect is going to have to perform a bit of excava- tion and archaeology to ferret them out. 

Chapter 4 categorizes the design decisions that architects have to make. Ta- ble 16.1 summarizes each category of architectural design decision, and it gives a list of requirements to look for that might affect that kind of decision. If a re- quirement affects the making of a critical architectural design decision, it is by definition an ASR. 





**16.2 Gathering aSrs by Interviewing Stakeholders** 

Say your project isn’t producing a comprehensive requirements document. Or it is, but it’s not going to have the QAs nailed down by the time you need to start your design work. What do you do? 

Architects are often called upon to help set the quality attribute requirements for a system. Projects that recognize this and encourage it are much more likely to be successful than those that don’t. Relish the opportunity. Stakeholders often have no idea what QAs they want in a system, and no amount of nagging is going to suddenly instill the necessary insight. If you insist on quantitative QA require- ments, you’re likely to get numbers that are arbitrary, and there’s a good chance that you’ll find at least some of those requirements will be very difficult to satisfy. 

Architects often have very good ideas about what QAs are exhibited by sim- ilar systems, and what QAs are reasonable (and reasonably straightforward) to provide. Architects can usually provide quick feedback as to which quality attri- butes are going to be straightforward to achieve and which are going to be prob- lematic or even prohibitive. And architects are the only people in the room who can say, “I can actually deliver an architecture that will do better than what you had in mind—would that be useful to you?” 

Interviewing the relevant stakeholders is the surest way to learn what they know and need. Once again, it behooves a project to capture this critical informa- tion in a systematic, clear, and repeatable way. Gathering this information from stakeholders can be achieved by many methods. One such method is the Quality Attribute Workshop (QAW), described in the sidebar. 

The results of stakeholder interviews should include a list of architectural drivers and a set of QA scenarios that the stakeholders (as a group) prioritized. This information can be used to do the following: 

- Refine system and software requirements 

- Understand and clarify the system’s architectural drivers 

- Provide rationale for why the architect subsequently made certain design 

  decisions 

- Guide the development of prototypes and simulations 

- Influence the order in which the architecture is developed 





**16.3 Gathering aSrs by understanding the business Goals** 

Business goals are the *raison d’être* for building a system. No organization builds a system without a reason; rather, the organization’s leaders want to further the mission and ambitions of their organization and themselves. Common business goals include making a profit, of course, but most organizations have many more concerns than simply profit, and in other organizations (e.g., nonprofits, charities, governments), profit is the farthest thing from anyone’s mind. 

Business goals are of interest to architects because they often are the precursor or progenitor of requirements that may or may not be captured in a requirements specification but whose achievement (or lack) signals a successful (or less than suc- cessful) architectural design. Business goals frequently lead directly to ASRs. 

There are three possible relationships between business goals and an architecture: 

1. *Business goals often lead to quality attribute requirements.* Or to put it another way, every quality attribute requirement—such as user-visible response time or platform flexibility or ironclad security or any of a dozen other needs—should originate from some higher purpose that can be described in terms of added value. If we ask, for example, “*Why* do you want this system to have a really fast response time?”, we might hear that this will differentiate the product from its competition and let the developing organization capture market share; or that this will make the soldier a more effective warfighter, which is the mission of the acquiring organization; or other reasons having to do with the satisfaction of some business goal. 
2. *Business goals may directly affect the architecture without precipitating a quality attribute requirement at all.* In Chapter 3 we told the story of the architect who designed a system without a database until the manager informed him that the database team needed work. The architecture was importantly affected without any relevant quality attribute requirement. 

3. *No influence at all.* Not all business goals lead to quality attributes. For example, a business goal to “reduce cost” may be realized by lowering the facility’s thermostats in the winter or reducing employees’ salaries or pensions. 

Figure 16.1 illustrates the major points just described. In the figure, the ar- rows mean “leads to.” The solid arrows are the ones highlighting relationships of most interest to architects. 

Architects often become aware of an organization’s business and business goals via osmosis—working, listening, talking, and soaking up the goals that are at work in an organization. Osmosis is not without its benefits, but more system- atic ways are possible. We describe one such way in the sidebar “A Method for Capturing Business Goals.” 





**16.4 capturing aSrs in a utility tree** 

As we have seen, ASRs can be extracted from a requirements document, captured from stakeholders in a workshop such as a QAW, or derived from business goals. It is helpful to record them in one place so that the list can be reviewed, refer- enced, used to justify design decisions, and revisited over time or in the case of major system changes. 

To recap, an ASR must have the following characteristics: 

- *A profound impact on the architecture.* Including this requirement will very likely result in a different architecture than if it were not included. 
- *A high business or mission value.* If the architecture is going to satisfy this requirement—potentially at the expense of not satisfying others—it must be of high value to important stakeholders. 

Using a single list can also help evaluate each potential ASR against these
criteria, and to make sure that no architectural drivers, stakeholder classes, or
business goals are lacking ASRs that express their needs.



Architects can use a construct called a *utility tree* for all of these purposes. A utility tree begins with the word “utility” as the root node. Utility is an expression of the overall “goodness” of the system. We then elaborate this root node by listing the major quality attributes that the system is required to exhibit. (We said in Chap- ter 4 that quality attribute names by themselves were not very useful. Never fear: we are using them only as placeholders for subsequent elaboration and refinement!) 

Under each quality attribute, record a specific refinement of that QA. For example, performance might be decomposed into “data latency” and “transac- tion throughput.” Or it might be decomposed into “user wait time” and “time to refresh web page.” The refinements that you choose should be the ones that are relevant to your system. Under each refinement, record the appropriate ASRs (usually expressed as QA scenarios). 

Some ASRs might express more than one quality attribute and so might ap- pear in more than one place in the tree. That is not necessarily a problem, but it could be an indication that the ASR tries to cover too much diverse territory. Such ASRs may be split into constituents that each attach to smaller concerns. 

Once the ASRs are recorded and placed in the tree, you can now evaluate them against the two criteria we listed above: the business value of the candidate ASR and the architectural impact of including it. You can use any scale you like, but we find that a simple “H” (high), “M” (medium), and “L” (low) suffice for each criterion. 

For business value, High designates a must-have requirement, Medium is for a requirement that is important but would not lead to project failure were it omitted. Low describes a nice requirement to have but not something worth much effort. 

For architectural impact, High means that meeting this ASR will profoundly affect the architecture. Medium means that meeting this ASR will somewhat af- fect the architecture. Low means that meeting this candidate ASR will have little effect on the architecture. 

Table 16.5 shows a portion of a sample utility tree drawn from a health care ap- plication called Nightingale. Each ASR is labeled with a pair of “H,” “M,” and “L” values indicating (a) the ASR’s business value and (b) its effect on the architecture. 

Once you have a utility tree filled out, you can use it to make important checks. For instance: 

- A QA or QA refinement without any ASR is not necessarily an error or omission that needs to be rectified, but it is an indication that attention should be paid to finding out for sure if there are unrecorded ASRs in that area. 
- ASRs that rate a (H,H) rating are obviously the ones that deserve the most attention from you; these are the most significant of the significant require- ments. A very large number of these might be a cause for concern about whether the system is achievable. 
- Stakeholders can review the utility tree to make sure their concerns are ad- dressed. (An alternative to the organization we have described here is to use stakeholder roles rather than quality attributes as the organizing rule under “Utility.”) 





### Tactics

#### 1. 可用性

**detect faults** 

Before any system can take action regarding a fault, the presence of the fault must be detected or anticipated. Tactics in this category include the following: 

■ *Ping/echo* refers to an asynchronous request/response message pair ex- changed between nodes, used to determine reachability and the round-trip delay through the associated network path. But the echo also determines that the pinged component is alive and responding correctly. The ping is  often sent by a system monitor. Ping/echo requires a time threshold to be set; this threshold tells the pinging component how long to wait for the echo before considering the pinged component to have failed (“timed out”). Standard implementations of ping/echo are available for nodes intercon- nected via IP. 

■ *Monitor*. A monitor is a component that is used to monitor the state of health of various other parts of the system: processors, processes, I/O, memory, and so on. A system monitor can detect failure or congestion in the network or other shared resources, such as from a denial-of-service attack. It orchestrates software using other tactics in this category to detect malfunctioning components. For example, the system monitor can initiate self-tests, or be the component that detects faulty time stamps or missed  heartbeats.1

- *Heartbeat* is a fault detection mechanism that employs a periodic message exchange between a system monitor and a process being monitored. A special case of heartbeat is when the process being monitored periodically resets the watchdog timer in its monitor to prevent it from expiring and thus signaling a fault. For systems where scalability is a concern, transport and processing overhead can be reduced by piggybacking heartbeat messages on to other control messages being exchanged between the process being monitored and the distributed system controller. The big difference between heartbeat and ping/echo is who holds the responsibility for initiating the health check—the monitor or the component itself. 
- *Time stamp.* This tactic is used to detect incorrect sequences of events, pri- marily in distributed message-passing systems. A time stamp of an event can be established by assigning the state of a local clock to the event imme- diately after the event occurs. Simple sequence numbers can also be used for this purpose, if time information is not important. 
- *Sanity checking* checks the validity or reasonableness of specific operations or outputs of a component. This tactic is typically based on a knowledge of the internal design, the state of the system, or the nature of the information under scrutiny. It is most often employed at interfaces, to examine a specific information flow. 
- *Condition monitoring* involves checking conditions in a process or device, or validating assumptions made during the design. By monitoring condi- tions, this tactic prevents a system from producing faulty behavior. The computation of checksums is a common example of this tactic. However, the monitor must itself be simple (and, ideally, provable) to ensure that it does not introduce new software errors. 
- *Voting.* The most common realization of this tactic is referred to as triple modular redundancy (TMR), which employs three components that do the same thing, each of which receives identical inputs, and forwards their out- put to voting logic, used to detect any inconsistency among the three output states. Faced with an inconsistency, the voter reports a fault. It must also decide what output to use. It can let the majority rule, or choose some com- puted average of the disparate outputs. This tactic depends critically on the voting logic, which is usually realized as a simple, rigorously reviewed and tested singleton so that the probability of error is low. 

**recover from faults** 

Recover-from-faults tactics are refined into *preparation-and-repair* tactics and *reintroduction* tactics. The latter are concerned with reintroducing a failed (but rehabilitated) component back into normal operation. 

Preparation-and-repair tactics are based on a variety of combinations of re- trying a computation or introducing redundancy. They include the following: 

- *Active redundancy (hot spare).* This refers to a configuration where all of the nodes (active or redundant spare) in a protection group2 receive and process identical inputs in parallel, allowing the redundant spare(s) to main- tain synchronous state with the active node(s). Because the redundant spare possesses an identical state to the active processor, it can take over from a failed component in a matter of milliseconds. The simple case of one active node and one redundant spare node is commonly referred to as 1+1 (“one plus one”) redundancy. Active redundancy can also be used for facilities protection, where active and standby network links are used to ensure high- ly available network connectivity. 
- *Passive redundancy (warm spare).* This refers to a configuration where only the active members of the protection group process input traffic;
   one of their duties is to provide the redundant spare(s) with periodic state updates. Because the state maintained by the redundant spares is only loosely coupled with that of the active node(s) in the protection group (with the looseness of the coupling being a function of the checkpointing mechanism employed between active and redundant nodes), the redundant nodes are referred to as warm spares. Depending on a system’s availability requirements, passive redundancy provides a solution that achieves a bal- ance between the more highly available but more compute-intensive (and expensive) active redundancy tactic and the less available but significantly less complex cold spare tactic (which is also significantly cheaper). (For an example of implementing passive redundancy, see the section on code tem- plates in Chapter 19.）
- *Spare (cold spare).* Cold sparing refers to a configuration where the re- dundant spares of a protection group remain out of service until a fail-over occurs, at which point a power-on-reset procedure is initiated on the redundant spare prior to its being placed in service. Due to its poor recovery
  performance, cold sparing is better suited for systems having only high-reliability (MTBF) requirements as opposed to those also having high-availability requirements.



**Prevent faults** 

Instead of detecting faults and then trying to recover from them, what if your sys- tem could prevent them from occurring in the first place? Although this sounds like some measure of clairvoyance might be required, it turns out that in many cases it is possible to do just that.3 

■ *Removal from service.* This tactic refers to temporarily placing a system component in an out-of-service state for the purpose of mitigating potential system failures. One example involves taking a component of a system out of service and resetting the component in order to scrub latent faults (such as memory leaks, fragmentation, or soft errors in an unprotected cache) be- fore the accumulation of faults affects service (resulting in system failure). Another term for this tactic is *software rejuvenation*. 

- *Transactions*. Systems targeting high-availability services leverage transac- tional semantics to ensure that asynchronous messages exchanged between distributed components are *atomic*, *consistent*, *isolated*, and *durable*. These four properties are called the “ACID properties.” The most common realiza- tion of the transactions tactic is “two-phase commit” (a.k.a. 2PC) protocol. This tactic prevents race conditions caused by two processes attempting to update the same data item. 





#### 可修改性

**reduce the Size of a Module** 

■ *Split module*. If the module being modified includes a great deal of capa- bility, the modification costs will likely be high. Refining the module into several smaller modules should reduce the average cost of future changes. 

**Increase cohesion** 

Several tactics involve moving responsibilities from one module to another. The purpose of moving a responsibility from one module to another is to reduce the likelihood of side effects affecting other responsibilities in the original module. 

■ *Increase semantic coherence*. If the responsibilities A and B in a module
 do not serve the same purpose, they should be placed in different modules. This may involve creating a new module or it may involve moving a re- sponsibility to an existing module. One method for identifying responsibil- ities to be moved is to hypothesize likely changes that affect a module. If some responsibilities are not affected by these changes, then those responsi- bilities should probably be removed. 

**reduce coupling** 

We now turn to tactics that reduce the coupling between modules. 

- *Encapsulate.* Encapsulation introduces an explicit interface to a module. This interface includes an application programming interface (API) and its associated responsibilities, such as “perform a syntactic transformation on an input parameter to an internal representation.” Perhaps the most common modifiability tactic, encapsulation reduces the probability that a change to one module propagates to other modules. The strengths of coupling that previously went to the module now go to the interface for the module. These strengths are, however, reduced because the interface limits the ways in which external responsibilities can interact with the module (perhaps through a wrapper). The external responsibilities can now only directly in- teract with the module through the exposed interface (indirect interactions, however, such as dependence on quality of service, will likely remain un- changed). Interfaces designed to increase modifiability should be abstract with respect to the details of the module that are likely to change—that is, they should hide those details. 
- *Use an intermediary* breaks a dependency. Given a dependency between re- sponsibility A and responsibility B (for example, carrying out A first requires carrying out B), the dependency can be broken by using an intermediary. The type of intermediary depends on the type of dependency. For example,  a publish-subscribe intermediary will remove the data producer’s knowledge of its consumers. So will a shared data repository, which separates readers of a piece of data from writers of that data. In a service-oriented architecture in which services discover each other by dynamic lookup, the directory service is an intermediary. 

- *Restrict dependencies* is a tactic that restricts the modules that a given mod- ule interacts with or depends on. In practice this tactic is achieved by re- stricting a module’s visibility (when developers cannot see an interface, they cannot employ it) and by authorization (restricting access to only authorized modules). This tactic is seen in layered architectures, in which a layer is only allowed to use lower layers (sometimes only the next lower layer) and in the use of wrappers, where external entities can only see (and hence depend on) the wrapper and not the internal functionality that it wraps. 
- *Refactor* is a tactic undertaken when two modules are affected by the same change because they are (at least partial) duplicates of each other. Code re- factoring is a mainstay practice of Agile development projects, as a cleanup step to make sure that teams have not produced duplicative or overly com- plex code; however, the concept applies to architectural elements as well. Common responsibilities (and the code that implements them) are “factored out” of the modules where they exist and assigned an appropriate home of their own. By co-locating common responsibilities—that is, making them submodules of the same parent module—the architect can reduce coupling. 
- *Abstract common services*. In the case where two modules provide not- quite-the-same but similar services, it may be cost-effective to implement the services just once in a more general (abstract) form. Any modification to the (common) service would then need to occur just in one place, reduc- ing modification costs. A common way to introduce an abstraction is by pa- rameterizing the description (and implementation) of a module’s activities. The parameters can be as simple as values for key variables or as complex as statements in a specialized language that are subsequently interpreted. 



1. **defer binding** 

   Because the work of people is almost always more expensive than the work of computers, letting computers handle a change as much as possible will almost always reduce the cost of making that change. If we design artifacts with built-in flexibility, then exercising that flexibility is usually cheaper than hand-coding a specific change. 

   Parameters are perhaps the best-known mechanism for introducing flexibility, and that is reminiscent of the abstract common services tactic. A parameterized function *f*(*a*, *b*) is more general than the similar function *f*(*a*) that assumes *b* = 0. When we bind the value of some parameters at a different phase in the life cycle than the one in which we defined the parameters, we are applying the defer binding tactic. 

In general, the later in the life cycle we can bind values, the better. However, putting the mechanisms in place to facilitate that late binding tends to be more expensive—yet another tradeoff. And so the equation on page 118 comes into play. We want to bind as late as possible, as long as the mechanism that allows it is cost-effective. 

Tactics to bind values at compile time or build time include these: 

- Component replacement (for example, in a build script or makefile) 

- Compile-time parameterization 

- Aspects 

  Tactics to bind values at deployment time include this: 

■ Configuration-time binding 

Tactics to bind values at startup or initialization time include this: ■ Resource files 

Tactics to bind values at runtime include these: 

- Runtime registration 

- Dynamic lookup (e.g., for services) 

- Interpret parameters 

- Startup time binding 

- Name servers 

- Plug-ins 

- Publish-subscribe 

- Shared repositories 

- Polymorphism 

  Separating building a mechanism for modifiability from using the mechanism to make a modification admits the possibility of different stakeholders being involved—one stakeholder (usually a developer) to provide the mechanism and another stakeholder (an installer, for example, or a user) to exercise it later, possibly in a completely different life-cycle phase. Installing a mechanism so that someone else can make a change to the system without having to change any code is sometimes called *externalizing* the change. 





#### 性能

- **control resource demand** 

  One way to increase performance is to carefully manage the demand for re- sources. This can be done by reducing the number of events processed by en- forcing a sampling rate, or by limiting the rate at which the system responds to events. In addition, there are a number of techniques for ensuring that the re- sources that you do have are applied judiciously: 

- - *Manage sampling rate*. If it is possible to reduce the sampling frequency at which a stream of environmental data is captured, then demand can be reduced, typically with some attendant loss of fidelity. This is common
     in signal processing systems where, for example, different codecs can be chosen with different sampling rates and data formats. This design choice is made to maintain predictable levels of latency; you must decide whether having a lower fidelity but consistent stream of data is preferable to losing packets of data. 
  - *Limit event response*. When discrete events arrive at the system (or element) too rapidly to be processed, then the events must be queued until they can be processed. Because these events are discrete, it is typically not desirable to “downsample” them. In such a case, you may choose to process events only up to a set maximum rate, thereby ensuring more predictable process- ing when the events are actually processed. This tactic could be triggered by a queue size or processor utilization measure exceeding some warning level. If you adopt this tactic and it is unacceptable to lose any events, then you must ensure that your queues are large enough to handle the worst case. If, on the other hand, you choose to drop events, then you need to choose a policy for handling this situation: Do you log the dropped events, or simply ignore them? Do you notify other systems, users, or administrators? 
  - *Prioritize events*. If not all events are equally important, you can impose a priority scheme that ranks events according to how important it is to service them. If there are not enough resources available to service them when they arise, low-priority events might be ignored. Ignoring events consumes min- imal resources (including time), and thus increases performance compared to a system that services all events all the time. For example, a building 

- 

1. **Manage resources** 

   Even if the demand for resources is not controllable, the management of these re- sources can be. Sometimes one resource can be traded for another. For example, intermediate data may be kept in a cache or it may be regenerated depending on time and space resource availability. This tactic is usually applied to the proces- sor but is also effective when applied to other resources such as a disk. Here are some resource management tactics: 

2. ■ *Increase resources.* Faster processors, additional processors, additional memory, and faster networks all have the potential for reducing latency.  Cost is usually a consideration in the choice of resources, but increasing the resources is definitely a tactic to reduce latency and in many cases is the cheapest way to get immediate improvement. 

- *Introduce concurrency*. If requests can be processed in parallel, the blocked time can be reduced. Concurrency can be introduced by processing differ- ent streams of events on different threads or by creating additional threads to process different sets of activities. Once concurrency has been intro- duced, scheduling policies can be used to achieve the goals you find desir- able. Different scheduling policies may maximize fairness (all requests get equal time), throughput (shortest time to finish first), or other goals. (See the sidebar.) 
- *Maintain multiple copies of computations*. Multiple servers in a client-serv- er pattern are replicas of computation. The purpose of replicas is to reduce the contention that would occur if all computations took place on a single server. A *load balancer* is a piece of software that assigns new work to one of the available duplicate servers; criteria for assignment vary but can be as simple as round-robin or assigning the next request to the least busy server. 
- *Maintain multiple copies of data. Caching* is a tactic that involves keeping copies of data (possibly one a subset of the other) on storage with different access speeds. The different access speeds may be inherent (memory versus secondary storage) or may be due to the necessity for network communica- tion. *Data replication* involves keeping separate copies of the data to reduce the contention from multiple simultaneous accesses. Because the data being cached or replicated is usually a copy of existing data, keeping the copies consistent and synchronized becomes a responsibility that the system must assume. Another responsibility is to choose the data to be cached. Some caches operate by merely keeping copies of whatever was recently request- ed, but it is also possible to predict users’ future requests based on patterns of behavior, and begin the calculations or prefetches necessary to comply with those requests before the user has made them. 
- *Bound queue sizes*. This controls the maximum number of queued arrivals and consequently the resources used to process the arrivals. If you adopt this tactic, you need to adopt a policy for what happens when the queues overflow and decide if not responding to lost events is acceptable. This tac- tic is frequently paired with the limit event response tactic. 
- *Schedule resources*. Whenever there is contention for a resource, the resource must be scheduled. Processors are scheduled, buffers are scheduled, and networks are scheduled. Your goal is to understand the characteristics of each resource’s use and choose the scheduling strategy that is compatible with it. (See the sidebar.) 